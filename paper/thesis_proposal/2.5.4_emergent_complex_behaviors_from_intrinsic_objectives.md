#### 2.5.4 Emergent Complex Behaviors from Intrinsic Objectives

Self-supervised and variational exploration methods can yield surprisingly advanced behaviors in high-dimensional domainsâ€”even without external rewards. Groth et al. (2021) observe that purely curiosity-driven policies can discover locomotion, object manipulation, or multi-stage maneuvers in complex environments. Over time, some behaviors may fade as the curiosity model saturates in certain regions, suggesting the need to *retain and reuse* valuable skills (Groth et al., 2021; Oudeyer & Kaplan, 2007). A notable instance is the notion of *Adaptive Curiosity*, in which the agent centers exploration on transitions or subgoals that continue to *improve* its learned representations or competences rather than fixating on random or saturated areas.
