## 2. Review of Related Literature

This section offers an integrative survey of foundational reinforcement learning (RL) algorithms and major developments in curiosity-driven exploration for partially random or stochastic environments. Early theoretical work (Tsitsiklis & Van Roy, 1997; Kakade, 2001; Peters & Schaal, 2008; Szepesvári, 2010) established the convergence properties of temporal-difference methods, policy gradient techniques, and actor-critic frameworks for continuous or high-dimensional RL. Meanwhile, intrinsic motivation emerged as a key concept in developmental robotics and psychology (Oudeyer & Kaplan, 2007), spurring computational approaches that reward knowledge acquisition (Baranes & Oudeyer, 2009), novelty (Tang et al., 2016), or prediction error (Pathak et al., 2017). Traditional count-based methods inspired new density-model variants (Bellemare et al., 2016; Ostrovski et al., 2017), exemplar-based exploration (Fu et al., 2017), and model-disagreement bonuses (Houthooft et al., 2016; Pathak et al., 2019; Mavor-Parker et al., 2021). Recent studies have tested large-scale or specialized curiosity formulations—combining random network distillation (Burda, Edwards, Storkey, & Klimov, 2018; Burda, Edwards, Pathak, et al., 2018) with variational option discovery (Achiam et al., 2018; Gregor et al., 2016; Eysenbach et al., 2018), latent Bayesian surprise (Mazzaglia et al., 2021), and robust active learning for humanoids (Frank et al., 2014). Intrinsic exploration continues to expand with hybrid reward models (Han et al., 2019; Huang et al., 2021; Yuan et al., 2025), new perspectives on stochastic worlds (Jarrett et al., 2022), and procedural or open-ended tasks (Raileanu & Rocktäschel, 2020; Sekar et al., 2020; Groth et al., 2021). Syntheses highlight the breadth of these contributions and open research challenges (Ladosz et al., 2022), emphasizing how adaptive curiosity can help agents learn in partially random domains through structured exploration, learning progress, and self-supervised skill discovery.
