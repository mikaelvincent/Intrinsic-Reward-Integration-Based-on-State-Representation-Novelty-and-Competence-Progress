#### 4.6.2 Performance Metrics

A robust set of metrics is used to evaluate each algorithm's behavior, learning stability, and exploration effectiveness (Bellemare et al., 2016; Pathak et al., 2017).

The following metrics come from established guidelines and are relevant for both extrinsic and intrinsic-reward-focused methods:
1. Extrinsic Episode Return
   - Definition: The sum of environment-provided rewards within an episode.
   - Usage: Tracks an agent's ability to solve the specified task. If tasks have sparse or delayed rewards, the final return becomes a critical indicator of success.
   - Reporting: Typically plotted as a running average (e.g., over the last 50 or 100 episodes) to reduce noise (Burda et al., 2018).
2. Success or Completion Rate
   - Definition: The fraction of episodes in which the agent satisfies a task-specific success criterion (reaching a goal, achieving a threshold).
   - Importance: Especially relevant for tasks with binary success conditions or heavily sparse rewards.
   - Example: In key-corridor grids (Raileanu and Rockt√§schel, 2020), measuring how often the agent obtains the goal key is more illustrative than raw returns.
3. Intrinsic Reward Curves
   - Definition: Tracks how the agent's internal bonus (curiosity, disagreement, prediction error, etc.) evolves over training time.
   - Interpretation: A rapidly decaying curve might indicate that the agent is no longer finding novel or uncertain states, whereas a stable or oscillating curve could suggest ongoing exploration or partial random phenomenon.
4. Coverage or Frontier Tracking
   - Discrete: Count of unique states visited or fraction of possible states (Bellemare et al., 2016).
   - Continuous: Approximate coverage using density estimators or k-nearest neighbors in feature space.
   - Significance: Reflects how broadly the agent explores beyond immediate extrinsic incentives.
5. Forward-Model Error
   - Definition: Mean-squared error or negative log likelihood of a learned forward dynamics or world model.
   - Usage: Investigated in methods that rely on model-based curiosity (Houthooft et al., 2016) or ensemble disagreement (Pathak et al., 2019).
   - Interpretation: Decreasing error indicates the agent's model of environment transitions is improving. Persistent high error in certain subregions may reflect irreducibly random transitions.
6. Other Task-Specific Metrics
   - Certain tasks may warrant specialized metrics like time-to-solve, distance traveled, or intermediate subgoal achievements. These are reported alongside the core metrics to better contextualize agent behavior.

By aggregating these metrics, experimenters can assess not only raw task performance but also the breadth and stability of the exploration process. This multi-faceted view is vital for understanding how well each algorithm addresses partially random or noisy domains (Baranes and Oudeyer, 2009).
