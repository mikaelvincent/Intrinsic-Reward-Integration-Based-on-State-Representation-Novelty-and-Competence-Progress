#### 3.4.5 Empirical Successes and Partially Random Contexts

Competence-based methods have proved effective in stochastic or procedurally generated settings, where naive novelty-seeking might chase irreducible noise. By measuring mastery improvements, the agent avoids focusing on transitions that cannot be learned (Baranes & Oudeyer, 2009; Frank et al., 2014). For example:

- Self-Generated Goals for Robotics
  - Frank et al. (2014) show that an intrinsically motivated humanoid can adapt motion planning, gradually improving behaviors like balancing or kicking while ignoring purely random sensor signals.
- Goal-Based RL
  - Agents that autonomously propose subgoals or represent them in latent spaces (Han et al., 2019) discover incremental steps of mastery, particularly helpful for long-horizon tasks with partial randomness in transitions.
- Skill Discovery
  - DIAYN skills (Eysenbach et al., 2018) or VALOR options (Achiam et al., 2018) remain robust even if certain aspects of the environment are random or unlearnable, because each skill’s objective centers on controllable distinctions.

In line with Section 2.2, these frameworks handle partially random subregions by effectively devaluing them once no competence improvement arises. Hence, adaptive curiosity emerges as a synergy of competence-based reward signals—focusing on tasks that provide incremental learning progress while ignoring ephemeral or purely noisy states.
