#### 2.4.5 Outlook

Procedural generation and partial randomness together raise the bar for truly general RL algorithms, preventing memorized solutions and demanding flexible, robust exploration. Techniques that discount irreducible noise (Mavor-Parker et al., 2021), unify multiple novelty signals (Huang et al., 2021), or rely on information gain in a Bayesian sense (Houthooft et al., 2016) show promise across diverse tasks. Concurrently, impact-driven methods (Raileanu & Rocktäschel, 2020) and skill discovery frameworks (Gregor et al., 2016; Eysenbach et al., 2018; Achiam et al., 2018) support structured exploration that persists under environment variations. As ongoing work refines these approaches—introducing sophisticated model ensembles, hybrid intrinsic signals, or hierarchical re-use—agents may achieve robust exploration even when each episode is unpredictably distinct and partially random.
