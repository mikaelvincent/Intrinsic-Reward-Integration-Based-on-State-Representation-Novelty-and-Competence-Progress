### 4.01 Research Environment and Respondents

This section presents the environments, tasks, and data sources used to investigate how agents equipped with adaptive curiosity mechanisms behave in partially random reinforcement learning (RL) settings. Although this thesis does not involve human participants, we refer to the artificial “actors” or “learning agents” as the subjects of study. Drawing on methods and insights from prior work on curiosity-driven RL (Bellemare et al., 2016; Burda, Edwards, Pathak, et al., 2018; Oudeyer & Kaplan, 2007; Pathak et al., 2017), we design multiple task environments with varying degrees of procedural generation and stochasticity. Below, we detail each environment, discuss the nature of the agent “respondents” in our computational experiments, and outline key properties motivating our chosen setup.
