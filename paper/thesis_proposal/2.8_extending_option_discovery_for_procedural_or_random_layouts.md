### 2.8 Extending Option Discovery for Procedural or Random Layouts

Impact-driven exploration, as proposed in RIDE (Raileanu and Rocktäschel, 2020), measures the distance in a learned embedding between consecutive states. This distance is scaled down by state visit counts within the same episode, thereby discouraging the agent from trivial toggling back and forth. The focus on impact—changes attributable to the agent's actions—helps isolate controllable transitions amidst random fluctuations. Consequently, RIDE has shown success in procedurally-generated environments where repeated states are rare and noise may abound.
