##### 4.4.2.5 Policy Optimization

- RL Backbone
  - The agent's total reward is $r_{\mathrm{ext}} + \lambda\,r_{\mathrm{int}}$. Any suitable policy gradient or actor-critic algorithm can be used (Sutton and Barto, 2018), e.g., PPO or TRPO.
- Periodic Updates
  - The forward model, embedding network, and region-splitting structure are updated periodically using recent trajectories. Each subregion's local error statistics are refreshed, yielding an updated $\mathrm{LP}_i$.
- Refinement
  - If a subregion accumulates more than a threshold number of samples, it may be split along the dimension of highest variance in $\phi(s)$, refining local error tracking (cf. Baranes and Oudeyer, 2009).
