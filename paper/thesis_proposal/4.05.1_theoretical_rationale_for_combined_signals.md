#### 4.05.1 Theoretical Rationale for Combined Signals

Combining multiple curiosity-driven signals can yield robust exploration strategies, addressing various pitfalls in partially random environments. Specifically, we focus on three complementary signals, namely:
- Bayesian Ensemble Information Gain (EBIG)
  - By measuring the KL divergence between old and new posterior parameters, the agent explicitly values data that refines its knowledge of the environment’s controllable transitions (Houthooft et al., 2016).
  - Once purely random transitions are recognized, all models converge to the same uncertain mean, causing the EBIG bonus to vanish. This counters the “noisy TV” trap commonly seen in naive prediction-error curiosity (Pathak et al., 2019).
- Aleatoric-Subtracted Prediction Error (ANAPE)
  - Subtracting predicted noise \(\mathrm{Tr}(\hat{\Sigma}_{t+1})\) from the raw error \(\|\mathbf{s}_{t+1}-\hat{\mu}_{t+1}\|^2\) effectively filters out unlearnable randomness (Mavor-Parker et al., 2021).
  - Combined with EBIG, the agent now has two distinct knowledge-based signals:
    - One from parameter-space uncertainty (EBIG).
    - Another from data-space noise discounting (ANAPE).
  - In principle, these two signals can complement each other: EBIG fosters systematic coverage, while ANAPE ensures we do not fixate on inherently random phenomena.
- Competence-Based Skill Progress (CBSP)
  - Intrinsically measuring how the agent’s mastery improves for sub-tasks or sub-regions helps avoid wasted exploration of states that yield no further skill gains (Baranes & Oudeyer, 2009).
  - For partially random tasks, competence-based exploration is known to discount unlearnable transitions, focusing on subgoals or controllable states (Eysenbach et al., 2018).
  - By mixing knowledge-based novelty (EBIG + ANAPE) with competence progress, we hypothesize a more balanced exploration strategy that is robust and skill-oriented.
