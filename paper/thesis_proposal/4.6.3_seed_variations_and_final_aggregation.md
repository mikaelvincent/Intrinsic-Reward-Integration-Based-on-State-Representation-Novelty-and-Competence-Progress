#### 4.6.3 Seed Variations and Final Aggregation

Multiple independent runs with distinct random seeds ensure that results are statistically robust and not artifacts of particular initialization or environment instances (Houthooft et al., 2016). This section specifies how many seeds are used and how the final performance is aggregated:
1. Number of Seeds
   - Each environment-method pair is typically trained using 5 or 10 seeds to balance statistical significance with computational cost (Burda et al., 2018).
   - For large or more complex tasks, fewer seeds may be used if resource constraints are severe, but with at least 3 seeds to avoid misleading outcomes.
2. Aggregation Method
   - After training completes for each seed, final performance metrics (e.g., average return, success rate) are aggregated by computing the mean and standard deviation across these seeds (Raileanu and Rocktäschel, 2020).
   - Learning curves are plotted with the mean metric over seeds, sometimes with shaded regions representing ±1 standard deviation or 95% confidence intervals.
3. Variance Reporting
   - Variation in performance across seeds can highlight an algorithm's stability or brittleness (Baranes and Oudeyer, 2009). Reporting the standard deviation or confidence intervals at key timesteps helps interpret the consistency of exploration outcomes.
   - If the environment is highly stochastic or partially random, large variance across seeds might imply that certain runs discovered beneficial strategies by chance, reinforcing the importance of multiple seeds for meaningful conclusions.

Collectively, these seed-based protocols help clarify how reliably an algorithm performs, especially in partially random tasks where different runs can exhibit disparate exploration paths (Houthooft et al., 2016).
