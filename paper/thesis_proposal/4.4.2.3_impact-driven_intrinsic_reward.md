##### 4.4.2.3 Impact-Driven Intrinsic Reward

For each transition $(s_t, a_t, s_{t+1})$, the agent obtains an impact measure:
$$
  \text{impact}(s_t,a_t,s_{t+1})
  = \|\phi(s_{t+1}) - \phi(s_t)\|.
$$

This captures the "agent-controllable" difference in embedding space (Raileanu and Rockt√§schel, 2020). Repetitive toggling is down-weighted by an episodic visitation counter $N_{\mathrm{ep}}(s_{t+1})$.
