#### 4.2.4 RIDE (Rewarding Impact-Driven Exploration)

RIDE (Raileanu & Rocktäschel, 2020) measures how the agent's actions affect a learned state embedding. The intrinsic reward for each transition is the $\ell_2$ distance in embedding space between consecutive states, downscaled by an episodic visitation counter for the newly visited state. This scheme rewards environment-impacting actions—such as toggling, moving, or picking up items—while penalizing repeatedly affecting the same states. Its design helps handle large procedurally generated or sparse-reward tasks where purely novelty-based methods might struggle.
