#### 4.2.2 ICM (Intrinsic Curiosity Module)

ICM (Pathak et al., 2017) augments a PPO agent with an extra curiosity-driven reward. It maintains two neural networks:
1. An inverse dynamics model that predicts the action taken, given consecutive states.
2. A forward dynamics model that predicts the latent representation of the next state, given the current latent state and action.

The agent's intrinsic reward is the forward model's prediction error. Large error indicates states or transitions that the model finds difficult to predict, thus driving exploration in underexplored regions. Because the latent representation comes from the inverse model, the forward model focuses on state aspects relevant to the agent's own actions.
