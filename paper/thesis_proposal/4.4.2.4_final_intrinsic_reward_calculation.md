##### 4.4.2.4 Final Intrinsic Reward Calculation

Putting it all together, each transition's intrinsic reward $r_{\mathrm{int}}$ comprises:
1. Learning Progress $\mathrm{LP}_i$ if $s_t\in R_i$.
2. Agent Impact in the embedding.

Hence,
$$
  r_{\mathrm{int}}(s_t,a_t,s_{t+1})
  = \alpha_{\mathrm{LP}} \,\mathrm{LP}_i
    \;+\;\alpha_{\mathrm{impact}} \,
      \frac{\|\phi(s_{t+1}) - \phi(s_t)\|}{1 + N_{\mathrm{ep}}(s_{t+1})},
$$
where subregion $i$ is the partition containing state $s_t$. The subregion's learning progress $\mathrm{LP}_i$ is zero if the region is deemed unlearnable (partial-random subspace).
