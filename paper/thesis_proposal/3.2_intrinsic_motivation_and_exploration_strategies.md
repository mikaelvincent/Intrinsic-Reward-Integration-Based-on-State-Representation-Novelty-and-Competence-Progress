### 3.2 Intrinsic Motivation and Exploration Strategies

Intrinsic motivation provides an internal mechanism for rewarding an agent’s exploration of the environment, particularly valuable when extrinsic rewards are sparse or absent (Oudeyer & Kaplan, 2007). Under this paradigm, an agent augments or replaces externally provided rewards \(r(s,a)\) with intrinsic signals \(r^i\) that reflect novelty, uncertainty reduction, or improved competence in mastering subtasks. Over the past decade, numerous formulations have emerged, each capturing a different mathematical or algorithmic perspective of “curiosity.” This section reviews significant approaches relevant to exploration in partially random or high-dimensional reinforcement learning (RL) environments. We present their formal definitions, key equations, and insights on how these methods address stochastic transitions or partial observability.
