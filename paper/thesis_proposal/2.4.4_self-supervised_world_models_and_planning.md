#### 2.4.4 Self-Supervised World Models and Planning

Amid heavy randomness, learning a robust **internal world model** can facilitate targeted exploration, as exemplified by:

- **Plan2Explore** (Sekar et al., 2020): A model-based approach that **plans** where to gather data to reduce **ensemble disagreement** in latent dynamics. Even when each new procedural level is unique, the agent’s global model can identify “knowledge gaps” and methodically explore them.  
- **Hierarchical Reuse**: Approaches like skill discovery (Achiam et al., 2018; Eysenbach et al., 2018) or curiosity in hindsight (Jarrett et al., 2022) can store partial policies that remain valid across random seeds—e.g., robust “door-unlocking” or “ledge-climbing” sub-policies—even if the environment’s overall layout is regenerated.
