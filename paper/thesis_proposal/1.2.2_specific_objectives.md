#### 1.2.2 Specific Objectives

To achieve the main objective, the specific objectives of this study are:
1. Develop a multi-component intrinsic reward mechanism that integrates state representation novelty, forward-model error, and learning progress signals in partially random environments, while systematically differentiating irreducibly random transitions from genuinely learnable dynamics to prevent prolonged exploration in unproductive regions.
2. Implement and refine the proposed mechanism within discrete and continuous tasks featuring partial randomness, ensuring sufficient adaptability and generalization across varying domain complexities.
3. Benchmark and compare the resulting exploratory behaviors against prominent curiosity-driven baselines, focusing on stability, sample efficiency, and performance under sparse or delayed extrinsic rewards.
