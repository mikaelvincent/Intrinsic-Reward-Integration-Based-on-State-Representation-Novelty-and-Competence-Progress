#### 2.4.1 Procedural Generation and Hard-Exploration Tasks

Classic benchmark environments like Montezuma’s Revenge or Venture highlight “hard-exploration” settings even under a single static layout (Bellemare et al., 2016; Ostrovski et al., 2017). Nonetheless, once agents memorize a specific arrangement, these challenges can be artificially reduced to reward exploitation. Procedural generation addresses that limitation by forcing generalization: an agent sees distinct room layouts (Raileanu & Rocktäschel, 2020) or uniquely arranged item distributions (Sekar et al., 2020) at every run. This design fosters open-ended and robust exploration strategies such as:
- Count-Based Extensions (Bellemare et al., 2016; Ostrovski et al., 2017)
  - Estimating pseudo-counts or density-based visitation metrics encourages novelty-seeking across an evolving set of states. Although effective in static mazes, these methods require clever generalization schemes—like neural density models or hashing—to remain tractable under continuous procedural variations (Tang et al., 2016; Ostrovski et al., 2017).
- Skill Discovery and Diversity (Gregor et al., 2016; Eysenbach et al., 2018; Achiam et al., 2018)
  - Some approaches learn latent skills (or “options”) by maximizing mutual information between a skill index and visited states. In procedural contexts, these self-discovered skills can help navigate novel layouts or effectively re-use fundamental exploration motifs (Eysenbach et al., 2018). However, purely diversity-driven exploration might still be lured by random transitions if the environment includes major stochastic elements (Jarrett et al., 2022).
