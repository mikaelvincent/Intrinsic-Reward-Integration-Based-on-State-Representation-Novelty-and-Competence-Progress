#### 3.2.2 Bayesian Information Gain and Ensemble Disagreement

Pure prediction-error can overvalue high-stochasticity events. In partially random settings, we desire epistemic uncertainty reduction, ignoring aleatoric (irreducible) noise (Mavor-Parker et al., 2021). Major solutions include:
- Variational Information Maximizing Exploration (VIME)
  - Houthooft et al. (2016) maintain a Bayesian neural network (BNN) for dynamics \(p(\theta \mid \mathcal{D}_t)\). After each transition, the agent updates the posterior from \(p(\theta\mid \mathcal{D}_t)\) to \(p(\theta\mid \mathcal{D}_{t+1})\), receiving an intrinsic reward:
    \[
    r^i_t = \mathbb{E}_{s_{t+1}}\Bigl[
      D_{\mathrm{KL}}\bigl[
        p(\theta\mid \mathcal{D}_{t+1}) \,\big\|\,
        p(\theta\mid \mathcal{D}_t)
      \bigr]
    \Bigr].
    \]
    In practice, the KL is approximated with a variational approach. Over time, purely random transitions yield negligible posterior updates, mitigating “noisy TV” traps.
- Ensemble Disagreement
  - Pathak et al. (2019) propose training an ensemble of forward models \(\{f_i\}_{i=1}^K\). Let each \(f_i\) predict \(\hat{s}_{t+1}^{(i)}\). The disagreement is typically:
    \[
    r^i_t \;=\; \mathrm{Var}_i\bigl[\hat{s}_{t+1}^{(i)}\bigr].
    \]
    True randomness yields consistent average predictions, so the variance remains low. Unexplored transitions with uncertain or incomplete knowledge maintain high ensemble variance. This effectively distinguishes noise from learnable novelty, ensuring the agent does not dwell on uncontrollable phenomena.
