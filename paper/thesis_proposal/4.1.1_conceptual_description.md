#### 4.1.1 Conceptual Description

The proposed method leverages a forward-modeling strategy to address partially random or noise-laden environments. It operates under the assumption that certain environment transitions are inherently stochastic, while other transitions can be captured by a learnable model. The central idea is to differentiate between unlearnable, irreducibly noisy dynamics and transitions that yield genuine knowledge gain. 

The approach subdivides the state-action space into local subregions. Each region tracks how effectively the agent's learned forward model predicts subsequent states or features. This evolution forms the basis of a learning progress metric. Whenever the model error in a subregion decreases across training steps, that subregion is deemed learnable and warrants ongoing exploration. Conversely, if the error remains persistently high, the region is flagged as containing random or unlearnable dynamics. These flagged subregions no longer receive significant exploration bonuses.

Furthermore, the method incorporates an impact-driven component, measuring how the agent's actions affect a learned embedding of the state. This additional term rewards state changes that are meaningfully influenced by the agent. By combining learning progress with an impact-based measure, the agent avoids spending undue time on irreducible noise. The result is a self-adaptive mechanism that highlights transitions offering genuine improvements in predictive accuracy, while discounting purely random state fluctuations.
