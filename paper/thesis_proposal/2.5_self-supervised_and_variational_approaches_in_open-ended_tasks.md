### 2.5 Self-Supervised and Variational Approaches in Open-Ended Tasks

Open-ended reinforcement learning (RL) settings challenge an agent to learn diverse behaviors without fixed external goals or strictly defined reward functions. In such contexts, **self-supervised** and **variational** methods have emerged to drive exploration, skill acquisition, and policy refinement in ways that transcend purely task-centric objectives. By leveraging *information-theoretic*, *ensemble-based*, or *latent variable* formulations, these methods encourage the agent to discover and master new behaviors or to refine its world-model purely from *intrinsic* feedback.
