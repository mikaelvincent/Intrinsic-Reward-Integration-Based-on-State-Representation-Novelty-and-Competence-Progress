### 2.1 Knowledge-Based and Predictive Exploration Methods

Knowledge-based approaches to exploration typically revolve around modeling how an agent acquires or refines its understanding of the environment in the absence of strong external feedback. Drawing on early theoretical reinforcement learning (RL) insights (Tsitsiklis & Van Roy, 1997; Kakade, 2001; Peters & Schaal, 2008; Szepesvári, 2010), these methods assign an intrinsic reward that represents *novelty*, *uncertainty reduction*, or *prediction error*. In other words, the agent’s internal knowledge model is rewarded for encountering transitions that expand or refine its learned representation of environment dynamics (Oudeyer & Kaplan, 2007; Baranes & Oudeyer, 2009).
