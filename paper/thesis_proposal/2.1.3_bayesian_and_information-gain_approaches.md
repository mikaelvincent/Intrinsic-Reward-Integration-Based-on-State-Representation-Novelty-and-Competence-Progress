#### 2.1.3 Bayesian and Information-Gain Approaches
A complementary class of **Bayesian** or **information-gain**-oriented methods quantifies how each new observation updates the agent’s belief about environment dynamics. For instance, Variational Information Maximizing Exploration (VIME) (Houthooft et al., 2016) uses a Bayesian neural network (BNN) to model transitions, rewarding steps that most reduce posterior uncertainty over the BNN’s parameters. This direct measure of *epistemic* uncertainty helps the agent focus on transitions that yield maximal knowledge gain and often naturally devalues transitions dominated by irreducible noise.

These ideas fit broader frameworks of *learning progress* or *predictive surprise* from prior developmental robotics concepts (Oudeyer & Kaplan, 2007; Baranes & Oudeyer, 2009). By assessing each step’s contribution to knowledge refinement, the agent systematically avoids spending excessive time on states that are either too predictable (no knowledge benefit) or entirely unpredictable (no meaningful improvement).
