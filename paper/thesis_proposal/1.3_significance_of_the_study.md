### 1.3 Significance of the Study

Existing curiosity-based exploration frameworks are effective primarily in environments with low stochasticity or repetitive state occurrences. However, they often struggle with "hard-exploration" tasks characterized by partial randomness or procedural generation, leading to inefficient exploration behaviors such as repeated visits to purely random transitions or a superficial focus on novel states without substantive skill acquisition (Jarrett et al., 2022; Mavor-Parker et al., 2021). To address these challenges, our multi-component adaptive curiosity mechanism is significant for several key reasons:
- By explicitly discounting irreducible noise, our approach seeks to overcome the common pitfall of novelty-driven agents becoming trapped in regions of pure randomness—the "noisy TV" effect (Mavor-Parker et al., 2021). Unlike naive exploration methods, our framework incorporates mechanisms that recognize and minimize curiosity toward inherently unpredictable transitions (Burda, Edwards, Pathak, et al., 2018; Pathak et al., 2017).
- Our competence-based exploration component promotes the development of meaningful, goal-directed behaviors and multi-step skills. Such capabilities are crucial in real-world scenarios where extrinsic rewards may be sparse, delayed, or difficult to define (Eysenbach et al., 2018; Oudeyer & Kaplan, 2007). Integrating skill-based exploration thus fosters more practical and robust behaviors than relying solely on state novelty or model uncertainty.
- Combining knowledge-based exploration (ensemble information gain), aleatoric uncertainty subtraction, and competence-based progression offers greater adaptability to large-scale or procedurally generated environments. This combination addresses limitations typically encountered when applying single-signal intrinsic motivation methods to complex scenarios (Bellemare et al., 2016; Raileanu & Rocktäschel, 2020).
- We aim to clarify how ensemble-based curiosity (Houthooft et al., 2016; Pathak et al., 2019), aleatoric noise discounting (Mavor-Parker et al., 2021), and competence progress (Baranes & Oudeyer, 2009) can be effectively combined through adaptive weighting strategies. Empirical validation of this approach will extend the theoretical understanding of intrinsic motivation methods, offering practical guidance for designing exploration strategies that handle partial randomness more effectively. Positive experimental outcomes can significantly advance the development of robust reinforcement learning (RL) agents applicable to various real-world scenarios.

In summary, our study seeks to overcome prominent challenges in current intrinsic exploration approaches. By successfully demonstrating improved exploration efficiency and skill mastery in partially random environments, our adaptive curiosity framework has the potential to substantially impact the design of next-generation RL agents for diverse applications, including robotics, open-ended simulation tasks, and human-agent interaction scenarios characterized by sparse feedback and inherent stochasticity.
