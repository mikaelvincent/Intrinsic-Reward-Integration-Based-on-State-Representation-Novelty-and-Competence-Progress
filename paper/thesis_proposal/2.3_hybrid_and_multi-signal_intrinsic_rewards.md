### 2.3 Hybrid and Multi-Signal Intrinsic Rewards

While single-source intrinsic motivation techniques—such as state-novelty bonuses (Bellemare et al., 2016; Ostrovski et al., 2017; Tang et al., 2016) or forward-model prediction errors (Burda, Edwards, Pathak, et al., 2018; Pathak et al., 2017)—have demonstrated robust exploration across a range of tasks, recent work highlights the advantages of hybrid or multi-signal formulations. In such approaches, multiple curiosity or exploration signals are unified under a single framework, with each signal offering a distinct perspective on which behaviors merit exploration (Han et al., 2019; Huang et al., 2021). By combining complementary signals (e.g., state-based novelty, action-conditional forward-model errors, density-based pseudo-counts, or skill-based competence measures), the agent can more selectively prioritize controllable, learnable, and informative transitions—particularly beneficial in partially random or highly stochastic settings.
